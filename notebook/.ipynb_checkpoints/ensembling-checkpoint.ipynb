{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb6891e-28d6-41d0-b22f-5b93dc95eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Modeling imports\n",
    "from xgboost  import XGBClassifier\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import numpy as np\n",
    "\n",
    "path = \"/Users/tcaron/Documents/Python Scripts/KaggleS3E5/data/\"\n",
    "\n",
    "train = pd.read_csv(path+\"train.csv\")\n",
    "test = pd.read_csv(path+\"test.csv\")\n",
    "origin = pd.read_csv(path+\"WineQT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e004447-0bac-4a0c-9524-af8dc137b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelfSplitTrain(df,test_size=0.2):\n",
    "    X = df.drop(columns=[\"Id\",\"quality\"])\n",
    "    y = df[[\"quality\"]].values\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=test_size,random_state=42)\n",
    "    return (X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67da9ad6-6738-43a6-9976-2b3728efb077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(train,test,columns=[\"pH\",\"fixed acidity\"]):\n",
    "    target = \"quality\"\n",
    "    df_trn = train.copy(deep = True)\n",
    "    df_tst = test.copy(deep = True)\n",
    "    df_trn[target] = df_trn[target].map({3:0,\n",
    "                    4:1,\n",
    "                    5:2,\n",
    "                    6:3,\n",
    "                    7:4,\n",
    "                    8:5})\n",
    "    pca_ = PCA(n_components=1 ,whiten= False)\n",
    "    df_trn[\"pca_1\"] = pca_.fit_transform(df_trn[columns])\n",
    "    df_tst[\"pca_1\"] = pca_.fit_transform(df_tst[columns])\n",
    "    \n",
    "    for cols in columns:\n",
    "        for df in [df_trn,df_tst]:\n",
    "            df.drop(cols, axis =1, inplace = True)\n",
    "    return (df_trn,df_tst)\n",
    "\n",
    "def sortie_prep(y_pred):\n",
    "    return y_pred +3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e4f2b8-c2f3-43b6-8c6e-c104b8349e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = test[[\"Id\"]]\n",
    "train = pd.concat([train,origin],ignore_index=True)\n",
    "train,test= pca(train, test)\n",
    "X_test = test.drop(columns = \"Id\")\n",
    "X_train,X_val,y_train,y_val = SelfSplitTrain(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b97e6-1160-44eb-b18a-9187e6679e89",
   "metadata": {},
   "source": [
    "def objective(trial):\n",
    "    target_clases = train[\"quality\"].value_counts()\n",
    "    n_classes = target_clases.nunique()\n",
    "    params_optuna = {\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0.01, 1.0),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.0001, 1.0),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.0001, 1.0),\n",
    "            'objective' : \" multi:softmax\",\n",
    "            'num_class': n_classes,\n",
    "        }\n",
    "    \n",
    "    n=trial.suggest_int('n_cv', 3, 10)\n",
    "    cv = StratifiedKFold(n,shuffle=True, random_state=42)\n",
    "    fold_scores = []\n",
    "    model = XGBClassifier(**params_optuna)\n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              eval_set= [(X_val,y_val)],\n",
    "              early_stopping_rounds = 50,\n",
    "              verbose=500)\n",
    "\n",
    "    pred_val = model.predict(X_val)\n",
    "\n",
    "    score = cohen_kappa_score(y_val,pred_val, weights='quadratic')\n",
    "    fold_scores.append(score)\n",
    "    return np.mean(fold_scores)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler = TPESampler())\n",
    "study.optimize(func=objective, n_trials=500)\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6984895b-117c-4ec9-b3ce-93843f3b6605",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {'max_depth': 9,\n",
    "              'learning_rate': 0.10170219296989287, \n",
    "              'n_estimators': 939,\n",
    "              'min_child_weight': 4,\n",
    "              'gamma': 0.2873681880046375,\n",
    "              'subsample': 0.6582602969527163,\n",
    "              'colsample_bytree': 0.7214980206445512,\n",
    "              'reg_alpha': 0.33596370591990027,\n",
    "              'reg_lambda': 0.5061368887005409,\n",
    "              'n_cv': 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8db2e77-bf7f-44b0-863d-b28e96ee5549",
   "metadata": {},
   "source": [
    "def objective2(trial):\n",
    "    target_clases = train[\"quality\"].value_counts()\n",
    "    n_classes = target_clases.nunique()\n",
    "    params_optuna = {\n",
    "            'lambda_l1': trial.suggest_float('lambda_l1', 0, 1),\n",
    "             'lambda_l2': trial.suggest_float('lambda_l2', 1, 10),\n",
    "             'num_leaves': trial.suggest_int('num_leaves', 40, 60),\n",
    "             'feature_fraction': trial.suggest_float('feature_fraction', 0, 1),\n",
    "             'bagging_fraction': trial.suggest_float('bagging_fraction', 0, 1),\n",
    "             'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "             'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "             'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 100),\n",
    "             'max_depth': trial.suggest_int('max_depth', 1, 20),\n",
    "             'num_iterations':trial.suggest_int('num_iterations', 100, 10000),\n",
    "             'objective' : \"multiclass\",\n",
    "             'metric' :'multi_logloss',\n",
    "        }\n",
    "    \n",
    "    n=trial.suggest_int('n_cv', 3, 10)\n",
    "    cv = StratifiedKFold(n,shuffle=True, random_state=42)\n",
    "    fold_scores = []\n",
    "    model = LGBMClassifier(**params_optuna)\n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              eval_set= [(X_val,y_val)],\n",
    "              early_stopping_rounds = 50,\n",
    "              verbose=500)\n",
    "\n",
    "    pred_val = model.predict(X_val)\n",
    "\n",
    "    score = cohen_kappa_score(y_val,pred_val, weights='quadratic')\n",
    "    fold_scores.append(score)\n",
    "    return np.mean(fold_scores)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler = TPESampler())\n",
    "study.optimize(func=objective2, n_trials=500)\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae77d035-8e2d-45c4-8ea6-9651706f3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgbm= {'lambda_l1': 0.06032958694472297,\n",
    "              'lambda_l2': 9.468684954887555,\n",
    "              'num_leaves': 49,\n",
    "              'feature_fraction': 0.42024961425671364,\n",
    "              'bagging_fraction': 0.6392661414098254,\n",
    "              'bagging_freq': 9,\n",
    "              'min_child_samples': 43,\n",
    "              'min_data_in_leaf': 14,\n",
    "              'max_depth': 8,\n",
    "              'num_iterations': 3723,\n",
    "              'n_cv': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e42e79f0-9914-4fdb-95e5-39d2a9efd853",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns='Id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "309de284-51cc-4ce1-8e6e-be2fd0a73844",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns='Id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80fc7e74-45b8-47dc-a098-574398a0c6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"n_cv\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.70027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalidation_0-mlogloss:1.11046\n",
      "[253]\tvalidation_0-mlogloss:1.14047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: n_cv\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42024961425671364, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42024961425671364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=43 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06032958694472297, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06032958694472297\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6392661414098254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6392661414098254\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.468684954887555, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.468684954887555\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[200]\tvalid_0's multi_logloss: 1.07675\n",
      "=== Fold 0 Cohen Kappa Score 0.4952705100646929 ===\n",
      "[10:50:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"n_cv\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.70060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalidation_0-mlogloss:1.00354\n",
      "[256]\tvalidation_0-mlogloss:1.01924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: n_cv\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42024961425671364, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42024961425671364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=43 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06032958694472297, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06032958694472297\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6392661414098254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6392661414098254\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.468684954887555, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.468684954887555\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[200]\tvalid_0's multi_logloss: 0.981606\n",
      "=== Fold 1 Cohen Kappa Score 0.5275744893828238 ===\n",
      "[10:51:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"n_cv\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:51:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.70885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalidation_0-mlogloss:1.06677\n",
      "[258]\tvalidation_0-mlogloss:1.10150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: n_cv\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42024961425671364, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42024961425671364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=43 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06032958694472297, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06032958694472297\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6392661414098254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6392661414098254\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.468684954887555, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.468684954887555\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[200]\tvalid_0's multi_logloss: 1.05825\n",
      "=== Fold 2 Cohen Kappa Score 0.5243337097397133 ===\n",
      "[10:51:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"n_cv\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:51:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.70597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalidation_0-mlogloss:1.01835\n",
      "[258]\tvalidation_0-mlogloss:1.03592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: n_cv\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42024961425671364, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42024961425671364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=43 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06032958694472297, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06032958694472297\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6392661414098254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6392661414098254\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.468684954887555, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.468684954887555\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[200]\tvalid_0's multi_logloss: 1.0206\n",
      "=== Fold 3 Cohen Kappa Score 0.4872595950923816 ===\n",
      "[10:51:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"n_cv\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:51:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.70212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalidation_0-mlogloss:1.04342\n",
      "[262]\tvalidation_0-mlogloss:1.06170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: n_cv\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42024961425671364, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42024961425671364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=43 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06032958694472297, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06032958694472297\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6392661414098254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6392661414098254\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.468684954887555, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.468684954887555\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[200]\tvalid_0's multi_logloss: 1.03043\n",
      "=== Fold 4 Cohen Kappa Score 0.5006236743375109 ===\n",
      "[10:51:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"n_cv\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:51:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.70003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalidation_0-mlogloss:0.99978\n",
      "[264]\tvalidation_0-mlogloss:1.02152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: n_cv\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42024961425671364, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42024961425671364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=43 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06032958694472297, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06032958694472297\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6392661414098254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6392661414098254\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.468684954887555, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.468684954887555\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[200]\tvalid_0's multi_logloss: 1.0046\n",
      "=== Fold 5 Cohen Kappa Score 0.5620644165983137 ===\n",
      "[10:51:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"n_cv\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:51:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.69708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalidation_0-mlogloss:0.98354\n",
      "[250]\tvalidation_0-mlogloss:1.00471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: n_cv\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42024961425671364, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42024961425671364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=43 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06032958694472297, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06032958694472297\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6392661414098254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6392661414098254\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.468684954887555, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.468684954887555\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[200]\tvalid_0's multi_logloss: 0.958506\n",
      "=== Fold 6 Cohen Kappa Score 0.5806168764184032 ===\n",
      "[10:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"n_cv\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.70831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalidation_0-mlogloss:1.07035\n",
      "[275]\tvalidation_0-mlogloss:1.09734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: n_cv\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42024961425671364, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42024961425671364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=43 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06032958694472297, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06032958694472297\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6392661414098254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6392661414098254\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.468684954887555, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.468684954887555\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[200]\tvalid_0's multi_logloss: 1.03333\n",
      "=== Fold 7 Cohen Kappa Score 0.518781266172158 ===\n",
      "[10:51:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"n_cv\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:51:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.69995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalidation_0-mlogloss:1.07251\n",
      "[254]\tvalidation_0-mlogloss:1.10277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: n_cv\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42024961425671364, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42024961425671364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=43 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06032958694472297, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06032958694472297\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6392661414098254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6392661414098254\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.468684954887555, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.468684954887555\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[200]\tvalid_0's multi_logloss: 1.04514\n",
      "=== Fold 8 Cohen Kappa Score 0.45651221955788257 ===\n",
      "[10:51:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"n_cv\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:51:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.69614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalidation_0-mlogloss:1.03841\n",
      "[261]\tvalidation_0-mlogloss:1.05994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: n_cv\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42024961425671364, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42024961425671364\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=43 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.06032958694472297, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06032958694472297\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6392661414098254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6392661414098254\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.468684954887555, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.468684954887555\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[200]\tvalid_0's multi_logloss: 0.974329\n",
      "=== Fold 9 Cohen Kappa Score 0.5543320491352426 ===\n",
      "=== Average Cohen Kappa Score 0.5207368806499122 ===\n"
     ]
    }
   ],
   "source": [
    "features = list(X_train.columns)\n",
    "TARGET = 'quality'\n",
    "k=10\n",
    "cv = StratifiedKFold(k, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "test_preds = []\n",
    "oof_preds = []\n",
    "oof_true = []\n",
    "for i, (train_idx,val_idx) in enumerate(cv.split(train[features],\n",
    "                                                 train[TARGET])):\n",
    "    \n",
    "    X_train = train.loc[train_idx, features]\n",
    "    y_train = train.loc[train_idx, TARGET]\n",
    "    X_val = train.loc[val_idx, features]\n",
    "    y_val = train.loc[val_idx, TARGET]\n",
    "    \n",
    "    #**************XGB***************\n",
    "    model1 = XGBClassifier(**params_xgb)\n",
    "    model1.fit(X_train,\n",
    "             y_train,\n",
    "             eval_set= [(X_val,y_val)],\n",
    "             early_stopping_rounds = 200,\n",
    "             verbose=200)\n",
    "    \n",
    "    pred_val1 = model1.predict(X_val)\n",
    "    \n",
    "    score1 = cohen_kappa_score(y_val,pred_val1, weights='quadratic')\n",
    "    #discard the predictions of poor performing models\n",
    "    if score1>0.36:\n",
    "        test_preds.append(model1.predict(test[features]))\n",
    "        fold_scores.append(score1)\n",
    "    \n",
    "    #************** Light GBM **************\n",
    "    model2 = LGBMClassifier(**params_lgbm)\n",
    "    model2.fit(X_train,\n",
    "             y_train,\n",
    "             eval_set= [(X_val,y_val)],\n",
    "             early_stopping_rounds = 200,\n",
    "             verbose=200)\n",
    "    \n",
    "    pred_val2 = model2.predict(X_val)\n",
    "    \n",
    "    score2 = cohen_kappa_score(y_val,pred_val2, weights='quadratic')\n",
    "    #discard the predictions of poor performing models\n",
    "    if score2>0.36:\n",
    "        test_preds.append(model2.predict(test[features]))\n",
    "        fold_scores.append(score2)\n",
    "    \n",
    "    oof_preds.extend(np.mean([pred_val1,pred_val2],axis=0))\n",
    "    oof_true.extend(y_val)\n",
    "    print(f'=== Fold {i} Cohen Kappa Score {np.mean([score1,score2])} ===')\n",
    "\n",
    "print(f'=== Average Cohen Kappa Score {np.mean(fold_scores)} ===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9330f5f4-b164-4229-849d-c0358316bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptunaRounder:\n",
    "\n",
    "    def __init__(self, y_true, y_pred):\n",
    "        self.y_true = y_true\n",
    "        self.y_pred = y_pred\n",
    "        self.labels = np.unique(y_true)\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        thresholds = []\n",
    "        for i in range(len(self.labels) - 1):\n",
    "            low = max(thresholds) if i > 0 else min(self.labels)\n",
    "            high = max(self.labels)\n",
    "            t = trial.suggest_float(f't{i}', low, high)\n",
    "            thresholds.append(t)\n",
    "        try:\n",
    "            opt_y_pred = self.adjust(self.y_pred, thresholds)\n",
    "        except: return 0\n",
    "        return cohen_kappa_score(self.y_true, opt_y_pred, weights='quadratic')\n",
    "\n",
    "    def adjust(self, y_pred, thresholds):\n",
    "        opt_y_pred = pd.cut(y_pred,\n",
    "                            [-np.inf] + thresholds + [np.inf],\n",
    "                            labels=self.labels)\n",
    "        return opt_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b57a8534-f79f-4aaa-ae20-042820a5730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n",
      "C:\\Users\\tcaron\\Anaconda3\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:194: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.log(np.exp(weighted_log_pdf - max_[:, np.newaxis]).sum(axis=1)) + max_\n"
     ]
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING) \n",
    "objective = OptunaRounder(oof_true, oof_preds)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, timeout=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "accd1f47-b8e7-41b0-9670-53f33435eac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized thresholds: [0.4652585475560227, 1.6794102627797107, 2.502690035308638, 3.4846453830703283, 4.194506308210782]\n",
      "     Id  quality\n",
      "0  2056        6\n",
      "1  2057        5\n",
      "2  2058        6\n"
     ]
    }
   ],
   "source": [
    "best_thresholds = sorted(study.best_params.values())\n",
    "print(f'Optimized thresholds: {best_thresholds}')\n",
    "test_preds = np.array(test_preds).mean(axis=0) \n",
    "opt_test_preds = objective.adjust(test_preds, best_thresholds).astype(int) +3\n",
    "Id[\"quality\"]=opt_test_preds\n",
    "print(Id.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33e264b7-d1bd-42aa-a93d-00720c8a0708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    630\n",
       "5    600\n",
       "7    142\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Id['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f833ec4c-61ad-42ab-af81-91210ef96e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Id.to_csv(\"sample_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8614df-d67d-4b30-a253-21f0b8943b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d29e3f-85e1-47be-b356-e16fc92d9f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd9bd52-605d-469d-b2df-6e5a281f6c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58d65c6-701a-40c0-8e49-53b056eb1afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1b538-d11b-4548-989d-e8c6ccd3ffd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0aac78-870b-45f0-bca8-44524828aed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4189d6-80ac-407a-8521-bdc47ce6780d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
